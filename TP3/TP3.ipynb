{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfe602-4165-410f-b1ab-dc8a517e32db",
   "metadata": {},
   "source": [
    "### ENSIMAG ‚Äì Grenoble INP ‚Äì UGA - Academic year 2024-2025\n",
    "# Introduction to Statistical Learning and Applications ([website](https://github.com/ISLA-Grenoble/2025-main))\n",
    "\n",
    "- Pedro L. C. Rodrigues -- `pedro.rodrigues@inria.fr`\n",
    "\n",
    "- Alexandre Wendling -- `alexandre.wendling@univ-grenoble-alpes.fr`\n",
    "\n",
    "***\n",
    "\n",
    "### ‚ö†Ô∏è General guidelines for TPs\n",
    "\n",
    "Each team shall upload its report on [Teide](https://teide.ensimag.fr/) before the deadline indicated at the course website. Please\n",
    "**include the name of all members** of the team on top of your report.\n",
    "The report should contain graphical representations and explanatory text. For each graph, axis names should be provided as well\n",
    "as a legend when it is appropriate. Figures should be explained by a few sentences in the text. Answer to\n",
    "the questions in order and refer to the question number in your report. Computations and\n",
    "graphics have to be performed in `python`. The report should be written as a jupyter notebook. This is a file format that allows users to format documents containing text written in markdown and `python` instructions. You should include all of the `python` instructions that you have used in the document so that it may be possible to replicate your results.\n",
    "\n",
    "***\n",
    "\n",
    "# üñ•Ô∏è TP3: Benchmarking classification methods (25 points)\n",
    "\n",
    "In this TP, we will be using mostly the packages `numpy`, `sklearn`, and `matplotlib`.\n",
    "\n",
    "## ‚ñ∂Ô∏è Part 1 (9 points)\n",
    "\n",
    "Consider a simulated dataset generated as follows:\n",
    "\n",
    "----\n",
    "### -- Step 1\n",
    "For each data point $i$, sample its label from a Bernoulli distribution $y_i \\sim \\mathcal{B}(p)$, i.e. $y_i = 1$ with probability $p$ and $y_i = 0$ with probability $1-p$. Note that to sample a random variable $B$ from $\\mathcal{B}(p)$ you can first sample $U$ from an uniform distribution as in `U = numpy.random.rand()` and then note that $B = \\mathbf{1}(U < p)$ where $\\mathbf{1}(\\cdot)$ is an indicator function.\n",
    "\n",
    "### -- Step 2\n",
    "\n",
    "Then, depending on the label $y_i \\in \\{0, 1\\}$ the associated data point $\\mathbf{x}_i \\in \\mathbb{R}^2$ is sampled as follows:\n",
    "\n",
    "$$\n",
    "  \\mathbf{x}_i \\mid y_i = 0 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0) \\quad \\text{and} \\quad \\mathbf{x}_i \\mid y_i = 1 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma}_1)\n",
    "$$\n",
    "\n",
    "where $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ is a multivariate normal distribution with mean $\\boldsymbol{\\mu}$ and covariance matrix $\\boldsymbol{\\Sigma}$ with pdf\n",
    "\n",
    "$$\n",
    "p_{\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})}(x) = \\dfrac{1}{2\\pi\\sqrt{\\det{\\boldsymbol{\\Sigma}}}}\\exp\\left(-\\dfrac{1}{2}\\big(\\boldsymbol{x}-\\boldsymbol{\\mu}\\big)^\\top \\boldsymbol{\\Sigma}^{-1}\\big(\\boldsymbol{x}-\\boldsymbol{\\mu}\\big)\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\boldsymbol{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\boldsymbol{\\mu}_1 = \\left[\\begin{array}{c}\\varepsilon \\\\ 0\\end{array}\\right] \\quad \\boldsymbol{\\Sigma}_0 = \\left[\\begin{array}{cc}0.5 & 0 \\\\ 0 & 0.5\\end{array}\\right] \\quad \\boldsymbol{\\Sigma}_1 = \\left[\\begin{array}{cc}0.4 & 0 \\\\ 0 & 0.4\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Note that to sample a $p$-dimensional vector $\\mathbf{x}$ from $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, you can use function `numpy.random.multivariate_normal`.\n",
    "\n",
    "----\n",
    "\n",
    "We will denote a set of $N$ data points $\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^N$ simulated with $\\varepsilon$ and $p$ as $\\mathcal{D}(N \\mid \\varepsilon, p)$. \n",
    "\n",
    "Define two datasets:\n",
    "$$\n",
    "\\mathcal{D}_\\text{train} = \\mathcal{D}(50 \\mid 2, 0.30) \\quad \\text{and} \\quad \\mathcal{D}_{\\text{test}} = \\mathcal{D}(10^3 \\mid 2, 0.30)~.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44a29f",
   "metadata": {},
   "source": [
    "**(a)** Plot the data points in $\\mathcal{D}_\\text{train} \\cup \\mathcal{D}_\\text{test}$ using different colors to indicate the classes of each data point and different pointing symbols to indicate whether a point is from the train or test set. You should use `matplotlib`'s function for scatterplots. Remember to always include a legend in your figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa6b66d",
   "metadata": {},
   "source": [
    "**(b)** What is the mathematical expression for the optimal Bayes classifier in this setting? And for its boundary region? Remember that the Bayes classifier can be written in terms of the ratio of $\\text{Prob}(Y = 1 \\mid \\mathbf{x})$ over $\\text{Prob}(Y = 0 \\mid \\mathbf{x})$ and that the values of $\\mathbf{x} \\in \\mathbb{R}^2$ for which this ratio is 1 are those defining its boundary. Beware, however, that in this exercise we're considering $\\text{Prob}(Y = 1) = p$ and $\\text{Prob}(Y = 0) = 1-p$, so they are not necessarily always equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ef27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1449b8",
   "metadata": {},
   "source": [
    "**(c)** Implement a Bayes classifier for this setup using scikit-learn's API as explained [here](https://scikit-learn.org/stable/developers/develop.html). This means that you will be writing a new classifier that follows the same logic and API as scikit-learn, but does not exist in the package. Use your implementation to estimate the error of the Bayes classifier on the samples from $\\mathcal{D}(10^4 \\mid 2, 0.3)$. How would you expect your results to change for other values of $\\varepsilon$? Plot a curve showing how the Bayes error rate changes for different choices $\\varepsilon$ (note that you will have to generate new datasets for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710efa70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8846b23d",
   "metadata": {},
   "source": [
    "**(d)** Given the structure of the model generating the datasets, which classifier presented in our lectures seems to be the most adequate? Justify your answer in terms of the assumptions behind the construction of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561b77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64b42e5b",
   "metadata": {},
   "source": [
    "**(e)** Using `sklearn`, train a LDA, a QDA, and a logistic regression classifier on $\\mathcal{D}_\\text{train}$ and estimate their errors on the samples from $\\mathcal{D}_\\text{test}$. How do their errors compare to the value obtained in (c)? Can we expect the gap between the Bayes error rate and test error for each classifier change when the number of samples in $\\mathcal{D}_{\\text{train}}$ in change? Justify your answer both theoretically and empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d382817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e731a24f",
   "metadata": {},
   "source": [
    "**(f)** Consider a new test set defined as $\\mathcal{D}'_\\text{test} = \\mathcal{D}(1000 \\mid 0.5, 0.7)$. Use the same classifiers trained in (e) and estimate their new test errors. Do you observe any difference in the results? Can you explain what is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de957995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a44482e-3638-4de4-8d02-52903f49ef1f",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Part 2 (8 points)\n",
    "\n",
    "In this part, we will consider a simulated benchmark similar to that from [Section 4.5.2 in James et al](https://www.statlearning.com/) presented and discussed in class. Our benchmark will compare the performance of four classifiers under three different scenarios.\n",
    "\n",
    "### -- Scenario 1\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & 0 \\\\ 0 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & 0 \\\\ 0 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(a)** Using `sklearn`, compare the performances of LDA, logistic regression, Gaussian naive Bayes, and QDA in this scenario. For this, you should generate 100 pairs of training-test datasets and evaluate the test errors for each of the classifiers. Use `matplotlib.pyplot.boxplot` to display the results for each of the classifiers along the different realizations. Explain the differences of the performances in terms of the assumptions of each classifier and the structure of the data generating mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29680d0-2610-4eb2-beaa-d5edfbbc4b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38597dce-b396-4b7d-aeaa-833a9612a28b",
   "metadata": {},
   "source": [
    "### -- Scenario 2\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(b)** Perform the same comparison as done for Scenario 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba9844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712aacb5-27ca-4a1e-a328-39c32071d048",
   "metadata": {},
   "source": [
    "### -- Scenario 3\n",
    "The observations for this scenario are generated as per:\n",
    "\n",
    "$$\n",
    "\\{(\\mathbf{x}_i, y_i)\\}_{i = 1}^{2N} = \\{(\\mathbf{x}_i, 0)\\}_{i = 1}^{N} \\cup \\{(\\mathbf{x}_i, 1)\\}_{i = 1}^{N}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{\\Sigma}_0) \\quad \\text{with} \\quad \\mathbf{\\mu}_0 = \\left[\\begin{array}{c}0 \\\\ 0\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_0 = \\left[\\begin{array}{cc}1 & -0.7 \\\\ -0.7 & 2\\end{array}\\right]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{x}_i | y_i = 1 \\sim \\mathcal{N}(\\mathbf{\\mu}_1, \\mathbf{\\Sigma}_1) \\quad \\text{with} \\quad \\mathbf{\\mu}_1 = \\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] \\quad \\text{and} \\quad \\mathbf{\\Sigma}_1 = \\left[\\begin{array}{cc}1 & +0.7 \\\\ +0.7 & 2\\end{array}\\right]~.\n",
    "$$\n",
    "\n",
    "The training set always have $N=20$ and the test set $N=5000$. \n",
    "\n",
    "**(c)** Perform the same comparison as done for Scenarios 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4456598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8841a873",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Part 3: Real data (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3076f",
   "metadata": {},
   "source": [
    "In this part we will consider the Titanic dataset available [here](https://www.kaggle.com/competitions/titanic/data). The goal here will be to build a machine learning model that predicts which passengers survived the Titanic shipwreck. Each passenger (i.e., data point) is composed of a set of categorical and continuous features, and its labels are either 0 (dead) or 1 (survived).\n",
    "\n",
    "First of all, you should download both the `training` and the `test` datasets.\n",
    "\n",
    "-- The `training` set should be used to build your machine learning models. The labels for each passenger are provided. Your model will be based on ‚Äúfeatures‚Äù like passengers‚Äô gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "-- The `test` set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "Follow the guidelines from [here](https://www.kaggle.com/competitions/titanic/overview) to understand how to submit the results of your predictions on the `test` set and obtain the score of your model.\n",
    "\n",
    "### Suggestions:\n",
    "\n",
    "-- Don't hesitate to do some exploratory data analysis before building your machine learning model. You chould check, for instance, which kind of cross-validator seems the most appropriate for assessing the score of your classifier : are the data points completely IID? are they ordered somehow? split into groups? Beware of all this.\n",
    "\n",
    "-- Since you will be handling predictors with different data types, it might be useful to take a look at the concept of `ColumnTransformer` from scikit-learn [here](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). You could also check these two videos about how to build complext pipelines [1](https://www.youtube.com/watch?v=7TZ7j4HSzmE) and [2](https://www.youtube.com/watch?v=lhMqqauXtW0).\n",
    "\n",
    "-- Take a look at the package [`skrub`](https://skrub-data.org/stable/). You would be surprised with how easy it is to get a very good score on this dataset using `tabular_learner`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090ef81",
   "metadata": {},
   "source": [
    "**(a)** Explain the feature engineering that you had to do with the dataset. If you've used `skrub`, explain how the encoding for each kind of predictor was decided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e6e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4de74450",
   "metadata": {},
   "source": [
    "**(b)** What type of classifier did you end up using? Why? What was your score in the public leaderboard from Kaggle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c55c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isla2025",
   "language": "python",
   "name": "isla2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
