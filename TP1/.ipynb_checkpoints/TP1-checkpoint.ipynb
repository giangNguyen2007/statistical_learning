{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfe602-4165-410f-b1ab-dc8a517e32db",
   "metadata": {},
   "source": [
    "### ENSIMAG ‚Äì Grenoble INP ‚Äì UGA - Academic year 2024-2025\n",
    "# Introduction to Statistical Learning and Applications ([website](https://github.com/ISLA-Grenoble/2025-main))\n",
    "\n",
    "- Pedro L. C. Rodrigues -- `pedro.rodrigues@inria.fr`\n",
    "\n",
    "- Alexandre Wendling -- `alexandre.wendling@univ-grenoble-alpes.fr`\n",
    "\n",
    "***\n",
    "\n",
    "### ‚ö†Ô∏è General guidelines for TPs\n",
    "\n",
    "Each team shall upload its report on [Teide](https://teide.ensimag.fr/) before the deadline indicated at the course website. Please\n",
    "**include the name of all members** of the team on top of your report.\n",
    "The report should contain graphical representations and explanatory text. For each graph, axis names should be provided as well\n",
    "as a legend when it is appropriate. Figures should be explained by a few sentences in the text. Answer to\n",
    "the questions in order and refer to the question number in your report. Computations and\n",
    "graphics have to be performed in `python`. The report should be written as a jupyter notebook. This is a file format that allows users to format documents containing text written in markdown and `python` instructions. You should include all of the `python` instructions that you have used in the document so that it may be possible to replicate your results.\n",
    "\n",
    "***\n",
    "\n",
    "# üñ•Ô∏è TP1: Analysis of prostate cancer data\n",
    "\n",
    "A medical study done on patients with prostate cancer aims to analyze the correlation between the prostate tumor volume and a set of clinical and morphometric variables. These variables include prostate specific antigens, a biomarker for prostate cancer, and a number of clinical measures (age, prostate weight, etc). The goal of this lab is to build a regression model to predict the severity of cancer, expressed by logarithm of the tumor volume -- `lcavol` variable -- from the following predictors:\n",
    "- `lpsa`: log of a prostate specific antigen\n",
    "- `lweight`: log of prostate weight\n",
    "- `age`: age of the patient\n",
    "- `lbph`: log of benign prostatic hyperplasia amount\n",
    "- `svi`: seminal vesicle invasion\n",
    "- `lcp`: log of capsular penetration\n",
    "- `gleason`: Gleason score (score on a cancer prognosis test)\n",
    "- `pgg45`: percent of Gleason scores 4 or 5\n",
    "\n",
    "The file `prostate.data`, available [here](https://github.com/ISLA-Grenoble/2025-main/blob/main/TP/TP1/prostate.data), contains measures of the logarithm of the tumor\n",
    "volume and of the 8 predictors for 97 patients. This file also contains an additional variable, called `train`, which will\n",
    "not be used and has to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad96533",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 1: Preliminary analysis of the data (1 points)\n",
    "\n",
    "**(a)** Download the file `prostate.data` and store it in your current folder. Read the dataset in using `pandas` as per\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"prostate.data\", sep=\"\\t\")\n",
    "```\n",
    "check how to use function `df.drop` to remove the first and last columns of `df` containing useless tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035833c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4be4b399",
   "metadata": {},
   "source": [
    "**(b)** The function defined below generates scatterplots (clouds of points) between all pairs of variables, allowing us to visually analyse the correlations between all variables in the dataframe. Explain what each line of function `pairplot` does and how it affects the final plot. You can use command `help` in the `python` shell to get the documentation of each function.\n",
    "\n",
    "``` \n",
    "# import the main plotting library for python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make a pairplot from scratch\n",
    "def pairplot(df, figsize=None):\n",
    "    if figsize is None:\n",
    "        figsize = (7.10, 6.70)\n",
    "    n_vars = df.shape[1]\n",
    "    fig, ax = plt.subplots(figsize=figsize, ncols=n_vars, nrows=n_vars)\n",
    "    plt.subplots_adjust(\n",
    "        wspace=0.10, hspace=0.10, left=0.05, right=0.95, bottom=0.05, top=0.95)\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_vars):\n",
    "            axij = ax[i][j]\n",
    "            i_name = df.columns[i]\n",
    "            j_name = df.columns[j]\n",
    "            axij.set_xticks([])\n",
    "            axij.set_yticks([])\n",
    "            axij.margins(0.1)\n",
    "            if i != j:\n",
    "                axij.scatter(df[i_name], df[j_name], s=10)\n",
    "            else:\n",
    "                axij.text(0.5, 0.5, i_name, fontsize=10,\n",
    "                              horizontalalignment='center',\n",
    "                              verticalalignment='center',\n",
    "                              transform = axij.transAxes)        \n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = pairplot(df)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88000c6f-b144-4aab-9422-d2a398d93d19",
   "metadata": {},
   "source": [
    "**(c)** Based on the generated figure, identify which variables seem the most correlated to `lcavol`. Also, infer the datatype for each of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e80eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d43cc90",
   "metadata": {},
   "source": [
    "**(d)** Recall the formula of correlation between two vectors and implement it with `numpy`. Explain the difference of your result when compared to `df.corr()`. Change the function `pairplot`to show the correlation coefficient on the upper triangle of the subplots. (Bonus) Use locally weighted scatterplot smoothing (LOWESS) to see the trends between pairs of features with `statsmodels.nonparametric.smoothers_lowess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a6775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72fddcf",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 2: Linear regression (7 points)\n",
    "\n",
    "In this exercise, we will perform a multiple linear regression to build a predictive model for the `lcavol` variable. The variables `gleason` and `svi` should be considered as qualitative variables. You can declare them as such with\n",
    "\n",
    "```\n",
    "df['svi'] = df['svi'].astype(\"category\")\n",
    "df['gleason'] = df['gleason'].astype(\"category\")\n",
    "```\n",
    "\n",
    "**(a)** Provide the mathematical equation of the regression model (note that you can use LaTeX to write equations) and define the diÔ¨Äerent parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd4423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "453a434f",
   "metadata": {},
   "source": [
    "**(b)** Before doing the linear regression of this TP, you will first have to handle the one-hot encoding of the categorical features of the dataframe. One way of doing this is as follows:\n",
    "\n",
    "```\n",
    "# encode the categorical features with dummy variables\n",
    "df_enc = pd.get_dummies(df, dtype=np.float64)\n",
    "# to drop one dummy column for each predictor\n",
    "df_enc = df_enc.drop(columns=['svi_0', 'gleason_6'])\n",
    "# add a column of ones to the dataframe\n",
    "df_enc['intercept'] = 1\n",
    "# extract the dataframe for predictors\n",
    "X = df_enc.drop(columns=['lcavol'])\n",
    "# get the observed values to predict\n",
    "y = df['lcavol']\n",
    "```\n",
    "\n",
    "- Why did we fix a `dtype` in `pd.get_dummies`?\n",
    "- Why did we drop two columns after the encoding?\n",
    "- Why did we add a column of ones to the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d306da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a9a3d0",
   "metadata": {},
   "source": [
    "**(c)** We will use the [`statsmodels`](https://www.statsmodels.org/) package to estimate the coefficients of the multiple linear regression as per:\n",
    "\n",
    "```\n",
    "# import required package\n",
    "import statsmodels.api as sm\n",
    "# this line does not fit the regression model per se but only builds it\n",
    "model = sm.OLS(y, X)\n",
    "# now we actually fit the model, e.g. calculate all of regression parameters\n",
    "results = model.fit()\n",
    "```\n",
    "\n",
    "Use command `results.sumary()` to get the statistical summary of the estimated coefficients. \n",
    "\n",
    "- Explain to what correspond the regression coeÔ¨Écients for the lines related to `svi` and `gleason`. \n",
    "\n",
    "- What would have happened in the regression if we did not do the one-hot encoding from above?\n",
    "\n",
    "- Comment the overall results of the regression as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d57548-1bef-404f-97de-262e7e83a959",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e73e35",
   "metadata": {},
   "source": [
    "**(d)** Use `results.conf_int` to get confidence intervals of level 95% for all the coeÔ¨Écients of the predictors. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1268a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e552976a",
   "metadata": {},
   "source": [
    "**(e)** What can you say about the eÔ¨Äects of the `lpsa` variable? Relate your answer to the $p$-value of a hypothesis test and a confidence interval. You can use `results.pvalues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035926ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f0c619",
   "metadata": {},
   "source": [
    "**(f)** Implement yourself a function that calculates the values of the parameters and their corresponding $p$-values. Bonus: explain why `numpy.linalg.inv` is not necessarily the best choice for estimating the parameters as compared to `numpy.linalg.solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349e9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82750a46",
   "metadata": {},
   "source": [
    "**(g)** Plot the predicted values of `lcavol` as a function of the actual values. For this, you can can use `results.get_prediction` to get predictions over `X` and then get its `predicted_mean` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c1408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a35276ca",
   "metadata": {},
   "source": [
    "**(h)** Plot the histogram of residuals as well as their qq-plot using `statsmodels` function `qqplot`. Can we admit that the residuals are normally distributed? Compute the residual sum of squares (RSS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1a32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dccefd",
   "metadata": {},
   "source": [
    "**(i)** What happens if predictors `lpsa` and `lcp` are removed from the multiple linear regression model? Note that you can pass a list of strings to `df.columns.drop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408f438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fdc2c4a-901e-4ee0-b384-dbb550c86c7d",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 3: Best subset selection (5 points)\n",
    "\n",
    "A regression model that uses $k$ predictors is said to be of size $k$. For instance, \n",
    "\n",
    "$$\n",
    "\\texttt{lcavol} = \\beta_1 \\texttt{lpsa} + \\beta_0 + \\varepsilon \\quad \\text{and} \\quad \\texttt{lcavol} = \\beta_1 \\texttt{lweight} + \\beta_0 + \\varepsilon\n",
    "$$\n",
    "\n",
    "are models of size one. The regression model without any predictor $\\texttt{lcavol} = \\beta_0 + \\varepsilon$ is a model of size 0.\n",
    "\n",
    "The goal of this exercise is to select the best model of size $k$ for each $k \\in \\{0, \\dots, 8\\}$.\n",
    "\n",
    "**(a)** Compute the residual sums of squares (RSS) for all models of size $k = 2$. Which model has the smallest RSS? Note that you can use a generator [`itertools.combination`](https://docs.python.org/3/library/itertools.html#itertools.combinations) to automatize for you all the combinations of $k$ elements among $n$.\n",
    "\n",
    "**(b)** For each value of $k \\in \\{0, \\dots, 8\\}$, select the set of predictors that minimizes the RSS. Plot these values as a function of $k$. Provide the names of the selected predictors for each value of $k$.\n",
    "\n",
    "**(c)** Do you think that minimizing the residual sum of squares is well suited to select the optimal size for the regression models? Justify your answer using what you've learned in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463fbfb-1fcb-462a-a677-79da92ad654e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaced33d-03be-4243-8161-7809defb262c",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 4: Split-validation (5 points)\n",
    "\n",
    "You have now found the best model for each of the nine possible model sizes. In the following, we wish to compare these nine diÔ¨Äerent regression models.\n",
    "\n",
    "**(a)** Give a brief overview of split-validation: how it works? Why it is not subject to the same issues raised in\n",
    "the item (c) of the previous Exercise?\n",
    "\n",
    "**(b)** Use function `train_test_split` from the `sklearn` package to split the dataset into a training and a validation (or test) partition. You can set `test_size=0.3`. For each of the nine models from before (i.e. those that minimized the RSS for each size $k$), compute the mean prediction error calculated over the samples from the test set and compare it to its corresponding mean training error. Plot a curve for each of these error as a function of size $k$. \n",
    "\n",
    "**(c)** Based on the previous results, choose the best model for this dataset, giving the parameter estimates for the model trained on the whole dataset (i.e. without splitting), and explain your choice.\n",
    "\n",
    "**(d)** What is the main limitation of split-validation ? Illustrate this issue on the cancer dataset. What could\n",
    "you do to address this problem? Code such alternative method and comment the result. Note that `sklearn` can provide you with many choices. See [here](https://scikit-learn.org/stable/model_selection.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924fd2e-c58c-4fa0-a71f-e823bbbbd87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b776123a-d559-42b6-815f-54d18a51012b",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è Exercise 5: Conclusion (2 points)\n",
    "\n",
    "What is your conclusion about the choice of the best model to predict `lcavol` ? Comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f199c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isla2025",
   "language": "python",
   "name": "isla2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
